{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from deltalake import write_deltalake, DeltaTable\n",
    "import warnings\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "    from opacus import PrivacyEngine\n",
    "    from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "except ImportError:\n",
    "    print(\"Installing PyTorch and Opacus.\")\n",
    "    subprocess.run(['pip', 'install', 'torch', 'opacus', '-q'], check=True)\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "    from opacus import PrivacyEngine\n",
    "    from opacus.utils.batch_memory_manager import BatchMemoryManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command(command, description=\"\"):\n",
    "    if description:\n",
    "        print(f\"\\n{'-'*60}\")\n",
    "        print(f\"{description}\")\n",
    "        print(f\"{'-'*60}\")\n",
    "    print(f\"{command}\")\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.stdout:\n",
    "        print(result.stdout)\n",
    "    if result.returncode != 0 and result.stderr:\n",
    "        print(f\"⚠️  {result.stderr}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total lift and splitting into training and test datasets.\n",
    "def prepare_dataset(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "\n",
    "    lift_columns = ['deadlift', 'candj', 'snatch', 'backsq']\n",
    "    existing_lifts = [col for col in lift_columns if col in df.columns]\n",
    "    \n",
    "    if existing_lifts:\n",
    "        df['total_lift'] = df[existing_lifts].sum(axis=1)\n",
    "    else:\n",
    "        print(\"No lift columns found.\")\n",
    "        np.random.seed(42)\n",
    "        df['total_lift'] = np.random.randint(500, 2000, size=len(df))\n",
    "    \n",
    "    df = df.dropna(subset=['total_lift'])\n",
    "    \n",
    "    # features.\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if 'total_lift' in numeric_cols:\n",
    "        numeric_cols.remove('total_lift')\n",
    "    \n",
    "    X = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "    y = df['total_lift']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DVC initialized.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('.git'):\n",
    "    print(\"Git not initialized.\")\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "if not os.path.exists('.dvc'):\n",
    "    run_command(\"dvc init\", \"Initializing DVC\")\n",
    "    run_command(\"git add .dvc .dvcignore\", \"Adding DVC files to Git\")\n",
    "    run_command('git commit -m \"Initialize DVC\"', \"Committing DVC setup\")\n",
    "else:\n",
    "    print(\"DVC initialized.\")\n",
    "\n",
    "\n",
    "if not os.path.exists('athletes.csv'):\n",
    "    print(\"File not found.\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DVC workflow.\n",
      "--------------------------------------------------------------------------------\n",
      "Original Dataset: (423006, 27)\n",
      "Columns: ['athlete_id', 'name', 'region', 'team', 'affiliate']...\n"
     ]
    }
   ],
   "source": [
    "# DVC workflow.\n",
    "print(\"-\"*80)\n",
    "print(\"DVC workflow.\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "\n",
    "df_original = pd.read_csv('athletes.csv')\n",
    "print(f\"Original Dataset: {df_original.shape}\")\n",
    "print(f\"Columns: {list(df_original.columns)[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "1. Work with given machine learning dataset, call this dataset version 1 (v1).\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------\n",
      "Adding v1 to DVC\n",
      "------------------------------------------------------------\n",
      "dvc add athletes_v1.csv\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add athletes_v1.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Adding DVC tracking files to Git\n",
      "------------------------------------------------------------\n",
      "git add athletes_v1.csv.dvc .gitignore\n",
      "\n",
      "------------------------------------------------------------\n",
      "Committing v1\n",
      "------------------------------------------------------------\n",
      "git commit -m \"Add dataset v1 (original)\"\n",
      "On branch main\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t.DS_Store\n",
      "\tSLIDE_1_Insights_Report.png\n",
      "\tSLIDE_2_Data_Lineage.png\n",
      "\tathletes.csv\n",
      "\tathletes_training.csv\n",
      "\tcreate_presentation_slides.py\n",
      "\tcredit_risk.py\n",
      "\tcredit_risk_cleaned.csv\n",
      "\tcredit_risk_data_lineage.png\n",
      "\tcredit_risk_eda_report.png\n",
      "\tcredit_risk_insights.txt\n",
      "\tcredit_risk_raw.csv\n",
      "\tcredit_risk_summary_stats.csv\n",
      "\tdata_versioning_local.py\n",
      "\tdata_versioning_local_OLD.py\n",
      "\tdata_versioning_partA.ipynb\n",
      "\tdelta_athletes_v1/\n",
      "\tdelta_athletes_v2/\n",
      "\teda_v1_dvc.png\n",
      "\teda_v2_dvc.png\n",
      "\tfinal_tool_comparison.png\n",
      "\trequirements.txt\n",
      "\tslides_partb.py\n",
      "\ttask13_linter_report.png\n",
      "\ttask16_dp_comparison_slide.png\n",
      "\tvenv/\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n",
      "\n",
      "Dataset v1 created and versioned with DVC and Git.\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*80)\n",
    "print(\"1. Work with given machine learning dataset, call this dataset version 1 (v1).\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "df_v1 = df_original.copy()\n",
    "df_v1.to_csv('athletes_v1.csv', index=False)\n",
    "\n",
    "run_command(\"dvc add athletes_v1.csv\", \"Adding v1 to DVC\")\n",
    "run_command(\"git add athletes_v1.csv.dvc .gitignore\", \"Adding DVC tracking files to Git\")\n",
    "run_command('git commit -m \"Add dataset v1 (original)\"', \"Committing v1\")\n",
    "\n",
    "print(\"Dataset v1 created and versioned with DVC and Git.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
